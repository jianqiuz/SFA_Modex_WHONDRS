---
title: "s19_sediments"
author: "Jianqiu Zheng"
date: "3/14/2022"
output: html_document
---

```{r setup, include=FALSE}
#Load the required packages
library(tidyverse)
library(dplyr)
library(reshape)
#Set the working directory 
setwd("~/Library/CloudStorage/OneDrive-PNNL/Documents/1SBR_SFA/WHONDRS_data/Preprocessing code")

#Load WHONDRS S19S data (presence/absence)
data <- read.csv('Processed_Clean_S19S_Water_Field_sediments_9-29_Data.csv')

#Load WHONDRS S19S molarity data 
mol <- read.csv('Processed_Clean_S19S_Water_Field_sediments_9-29_Mol.csv')

```

## creating a lookup table with mass
```{r cars}
#Change column header 
names(data)[1] <- "Mass"

#Create ID column
data <- mutate(data, ID = row_number())
mol <- mutate(mol, ID = row_number())

#Subset mol to get df of just Mass and MolForm
mol_subset <- mol %>% select(ID, Mass, MolForm)

#Merge data and mol
df <- merge(data, mol_subset, by= "ID")

#Select wanted columns and remove NAs and 0 counts
df_subset <- df %>% 
              select(-one_of('ID', 'Mass.y')) %>% 
              select('Mass.x', 'MolForm', everything()) %>% 
              pivot_longer(!c(Mass.x, MolForm), names_to = "Site_ID", 
                           values_to = "Count") %>%
              filter(Count != 0)%>%
              na.omit()



#Extract the sample type (water or sediment)
df$Type <- ifelse(grepl("Sed", df$Site_ID), "Sediment", "Water")

sed_df <- filter(df, Type == "Sediment")
water_df <- filter(df, Type == "Water")

#Write df to csv file
write.csv(sed_df,file = "S19S_sed_with_metadata.csv")
# write.csv(water_df,file = "S19S_water_with_metadata.csv")

```


```{r cars}
#test read csv file to make sure ID is character
test<- read.csv("S19S_sed_with_metadata.csv",colClasses=c("ID"="character"))
```


```{r cars}
#test read csv file to make sure ID is character
meta<- read.csv("S19S_sed_with_metadata.csv",colClasses=c("ID"="character"))

##load modeling results
ther<- read.csv("S19S_sed_oxy.csv")



#Select wanted columns 
ther_subset <- ther %>% 
              select('delGcat','lambda','ne','stoichMet_donor','stoichMet_acceptor','stoichMet_hco3','C_num','CUE')

#Select wanted columns 
meta_subset <- meta %>% 
              select('ID','Position','MolForm')

##match ID, peaks and predictions
ther_meta<- cbind(meta_subset,ther_subset)

unique(ther_meta$ID)


```


#plot energy distribution
##no significant pattern 

```{r mean}


#density distribution plot
plot1<-ggplot(data=ther_meta, aes(x=lambda))+ 
  #geom_histogram(aes(y=..density..,color=Amendment, fill=Amendment),binwidth=40,alpha=0.2, position="identity")+ 
  geom_density(aes(color=ID), size=1)+
  scale_x_continuous(limits=c(0,0.2))+
  #scale_y_continuous(limits=c(0, 2e-4),breaks=seq(0,2e-4, by=1e-4))+
  #scale_fill_manual(values = c("#E7B800","#0073C2FF", "#FC4E07","#00AFBB")) +
  #scale_color_manual(values = c("#E7B800","#0073C2FF", "#FC4E07","#00AFBB"))+
  #theme_pubr(border=TRUE)+theme(legend.position=c(0.12,0.75))+  theme(panel.grid.minor.x=element_line(linetype="dashed", color="gray",size=0.2))+
  theme(panel.grid.major.x=element_line(linetype="dashed", color="gray",size=0.2))
## blue, red, yellow:  "#0073C2FF", "#FC4E07","#E7B800"
plot1

```

#Calculating mean of each ID/Position
```{r mean}
mean_meta<-ther_meta%>%
  group_by(ID, Position)%>%
  summarise(lambda=median(lambda), soichMet_donor=mean(stoichMet_donor), stoichMet_acceptor=mean(stoichMet_acceptor), stoichMet_hco3=mean(stoichMet_hco3), C_num=mean(C_num), CUE=median(CUE))

```

#Seperating data by ID and position

```{r sep}
#Select upstream sediment samples 
up.data = subset(ther_meta, Position=="Up")
mid.data = subset(ther_meta, Position=="Mid")
low.data = subset(ther_meta, Position=="Down")


#Select for variables of interest---up
var_study <- unique (up.data$ID) %>% sort() #unique study names
length(var_study)
#For each site subset, eliminate rows with 0 and format headers
for (i in 1:length(var_study)) {
   sub_study <- subset(up.data, ID == var_study[i])
  write.csv(sub_study,file=paste0(i,"_up.csv"),row.names = FALSE)
}

#Select for variables of interest--mid
var_study <- unique (mid.data$ID) %>% sort() #unique study names
length(var_study)
#For each site subset, eliminate rows with 0 and format headers
for (i in 1:length(var_study)) {
   sub_study <- subset(mid.data, ID == var_study[i])
  write.csv(sub_study,file=paste0(i,"_mid.csv"),row.names = FALSE)
}


#Select for variables of interest---down
var_study <- unique (low.data$ID) %>% sort() #unique study names
length(var_study)
#For each site subset, eliminate rows with 0 and format headers
for (i in 1:length(var_study)) {
   sub_study <- subset(low.data, ID == var_study[i])
  write.csv(sub_study,file=paste0(i,"_low.csv"),row.names = FALSE)
}

```

#Extract incubation and NPOC data
```{r cars}

rates<- read.csv("WHONDRS_S19S_Sediment_Incubations_Respiration_Rates.csv")
obv <- rates %>% select(Sample_ID, rate_mg_per_L_per_h)
colnames(obv)<-c('ID', 'rate')

raw_npoc<- read.csv("WHONDRS_S19S_Sediment_NPOC_complete.csv")
colnames(raw_npoc)<-c('study','ID', 'conc')
npoc<-raw_npoc%>% select(ID, conc)


#Select samples
up_obv <- obv[grep("SED_INC-U",obv$ID), ] ##grep--globally search for a regular expression and print matching lines---return lines
colnames(up_obv)<-c('ID', 'rate')
unique(up_obv$ID)
up_obv$site = str_extract(up_obv$ID, "[0-9]{4}")
up_obv<-up_obv[,-1]

up_npoc<- npoc[grep("Sed_Field_ICR-U",npoc$ID), ] 
up_npoc$site = str_extract(up_npoc$ID, "[0-9]{4}")
up_npoc<-up_npoc[,-1] 

up<-merge(up_obv,up_npoc, by='site')
colnames(up)<-c('site','resp','npoc')
colnames(up.data)[1]<-"site"

#Merge data by site number--modeling results and measured concentration and rates
testtt<-merge (up.data, up,by='site') 
write.csv(testtt,'up_all.csv', row.names = FALSE)

#--------------------
#Select samples
mid_obv <- obv[grep("SED_INC-M",obv$ID), ] ##grep--globally search for a regular expression and print matching lines---return lines
colnames(mid_obv)<-c('ID', 'rate')
unique(mid_obv$ID)
mid_obv$site = str_extract(mid_obv$ID, "[0-9]{4}")
mid_obv<-mid_obv[,-1]

mid_npoc<- npoc[grep("Sed_Field_ICR-M",npoc$ID), ] 
mid_npoc$site = str_extract(mid_npoc$ID, "[0-9]{4}")
mid_npoc<-mid_npoc[,-1] 

mid<-merge(mid_obv,mid_npoc, by='site')
colnames(mid)<-c('site','resp','npoc')
colnames(mid.data)[1]<-"site"

#Merge data by site number--modeling results and measured concentration and rates
mid_all<-merge (mid.data, mid,by='site') 
write.csv(mid_all,'mid_all.csv', row.names = FALSE)


#--------------------
#Select samples
low_obv <- obv[grep("SED_INC-D",obv$ID), ] ##grep--globally search for a regular expression and print matching lines---return lines
colnames(low_obv)<-c('ID', 'rate')
unique(low_obv$ID)
low_obv$site = str_extract(low_obv$ID, "[0-9]{4}")
low_obv<-low_obv[,-1]

low_npoc<- npoc[grep("Sed_Field_ICR-D",npoc$ID), ] 
low_npoc$site = str_extract(low_npoc$ID, "[0-9]{4}")
low_npoc<-low_npoc[,-1] 

low<-merge(low_obv,low_npoc, by='site')
colnames(low)<-c('site','resp','npoc')
colnames(low.data)[1]<-"site"

#Merge data by site number--modeling results and measured concentration and rates
low_all<-merge (low.data, low,by='site') 
write.csv(low_all,'low_all.csv', row.names = FALSE)


```


#Summerize modeling results for graphing

```{r sep}
up<- read.csv("up_all.csv",colClasses=c("site"="character"))
mid<- read.csv("mid_all.csv",colClasses=c("site"="character"))
low<- read.csv("low_all.csv",colClasses=c("site"="character"))


#Select for variables of interest---up
var_study <- unique (up$site) %>% sort() #unique study names
length(var_study)
#For each site subset, eliminate rows with 0 and format headers
model_sum<- function (up){
  t_results <- data.frame() 
  
  for (i in 1:length(var_study)) {
   sub_study <- subset(up, site == var_study[i])
   #calculate 3 rates, with stoichiometry, concentration, and umax
   sub_study$rate1<-exp(-abs(sub_study$stoichMet_donor))
   sub_study$rate2<-exp(-abs(sub_study$stoichMet_donor)/sub_study$npoc/1) ##value of vh
   sub_study$rate3<-exp(-abs(sub_study$stoichMet_donor)/sub_study$npoc/0.1) ##value of vh
   sub_study$rate4<- exp(-abs(sub_study$stoichMet_donor)/sub_study$npoc/0.01) #add umax
   sub_study$rate5<- exp(-abs(sub_study$stoichMet_donor)/sub_study$npoc/0.001) #add umax
   sub_study$rate6<- exp(-abs(sub_study$stoichMet_donor)/sub_study$npoc/0.0001) #add umax
   #sub_study$rate5<-3/sub_study$ne * exp(-abs(sub_study$stoichMet_donor)/sub_study$npoc/0.1) #add umax
   sub_mean <- colMeans(sub_study[sapply(sub_study, is.numeric)])
   test<-data.frame(t(sub_mean))
   test$site<-sub_study$site[1]
   test$Position<-sub_study$Position[1]
   testnew<- test[,c(17,18,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16) ]

   t_results<- rbind(t_results, testnew)
  }
  return(t_results)
}
stat_sum<-model_sum(up)
stat_sum2<-na.omit(stat_sum)

write.csv(stat_sum2,"stat_sum_up.csv",row.names = FALSE)


#Select for variables of interest---mid
var_study <- unique (mid$site) %>% sort() #unique study names
length(var_study)
#For each site subset, eliminate rows with 0 and format headers
model_sum<- function (mid){
  t_results <- data.frame() 
  
  for (i in 1:length(var_study)) {
   sub_study <- subset(mid, site == var_study[i])
   #calculate 3 rates, with stoichiometry, concentration, and umax
   sub_study$rate1<-exp(-abs(sub_study$stoichMet_donor))
   sub_study$rate2<-exp(-abs(sub_study$stoichMet_donor)/sub_study$npoc/1) ##value of vh
   sub_study$rate3<-exp(-abs(sub_study$stoichMet_donor)/sub_study$npoc/0.1) ##value of vh
   sub_study$rate4<- exp(-abs(sub_study$stoichMet_donor)/sub_study$npoc/0.01) #add umax
   sub_study$rate5<- exp(-abs(sub_study$stoichMet_donor)/sub_study$npoc/0.001) #add umax
   sub_study$rate6<- exp(-abs(sub_study$stoichMet_donor)/sub_study$npoc/0.0001) #add umax
   #sub_study$rate5<-3/sub_study$ne * exp(-abs(sub_study$stoichMet_donor)/sub_study$npoc/0.1) #add umax
   sub_mean <- colMeans(sub_study[sapply(sub_study, is.numeric)])
   test<-data.frame(t(sub_mean))
   test$site<-sub_study$site[1]
   test$Position<-sub_study$Position[1]
   testnew<- test[,c(17,18,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16) ]

   t_results<- rbind(t_results, testnew)
  }
  return(t_results)
}
stat_sum<-model_sum(mid)
stat_sum2<-na.omit(stat_sum)

write.csv(stat_sum2,"stat_sum_mid.csv",row.names = FALSE)


#Select for variables of interest---low
var_study <- unique (low$site) %>% sort() #unique study names
length(var_study)
#For each site subset, eliminate rows with 0 and format headers
model_sum<- function (low){
  t_results <- data.frame() 
  
  for (i in 1:length(var_study)) {
   sub_study <- subset(low, site == var_study[i])
   #calculate 3 rates, with stoichiometry, concentration, and umax
   sub_study$rate1<-exp(-abs(sub_study$stoichMet_donor))
   sub_study$rate2<-exp(-abs(sub_study$stoichMet_donor)/sub_study$npoc/1) ##value of vh
   sub_study$rate3<-exp(-abs(sub_study$stoichMet_donor)/sub_study$npoc/0.1) ##value of vh
   sub_study$rate4<- exp(-abs(sub_study$stoichMet_donor)/sub_study$npoc/0.01) #add umax
   sub_study$rate5<- exp(-abs(sub_study$stoichMet_donor)/sub_study$npoc/0.001) #add umax
   sub_study$rate6<- exp(-abs(sub_study$stoichMet_donor)/sub_study$npoc/0.0001) #add umax
   #sub_study$rate5<-3/sub_study$ne * exp(-abs(sub_study$stoichMet_donor)/sub_study$npoc/0.1) #add umax
   sub_mean <- colMeans(sub_study[sapply(sub_study, is.numeric)])
   test<-data.frame(t(sub_mean))
   test$site<-sub_study$site[1]
   test$Position<-sub_study$Position[1]
   testnew<- test[,c(17,18,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16) ]

   t_results<- rbind(t_results, testnew)
  }
  return(t_results)
}
stat_sum<-model_sum(mid)
stat_sum2<-na.omit(stat_sum)

write.csv(stat_sum2,"stat_sum_low.csv",row.names = FALSE)

```

#graphing
```{r graph}
library(ggplot2)
library(ggpubr)
library(scales)
theme_pubclean()

up<- read.csv("stat_sum_up.csv",colClasses=c("site"="character"))
mid<- read.csv("stat_sum_mid.csv",colClasses=c("site"="character"))
low<- read.csv("stat_sum_low.csv",colClasses=c("site"="character"))
all<-rbind(up, mid, low)
all$xlab<-1/all$npoc

test1<-cor(all$resp, all$rate1, method='pearson')
test2<-cor(all$resp, all$rate2, method='pearson')
test3<-cor(all$resp, all$rate3, method='pearson')
test4<-cor(all$resp, all$rate4, method='pearson')
test5<-cor(all$resp, all$rate5, method='pearson')
test6<-cor(all$resp, all$rate6, method='pearson')


plot1<-ggplot(data=all, aes(x=resp, y=rate6))+ 
  geom_point(aes(),shape=1,stroke=1,size=2)+
  #geom_line(aes(linetype=trt),size=0.5,color="#868686FF")+
  #scale_x_continuous(limits=c(-1,5))+
  #scale_y_continuous(labels=scaleFUN)+
  #facet_grid(~scen, labeller=as_labeller(trtlab))+
  #scale_fill_manual(values = c("#868686FF","#E7B800", "#0073C2FF","#FC4E07","#00AFBB")) +
  #scale_color_manual(values = c("#868686FF","#E7B800","#0073C2FF", "#FC4E07","#00AFBB"))+
  theme_pubr(border=TRUE)+theme(legend.position="none")+theme(strip.text=element_text(size=14, face="bold"))
plot1


pred_tem<-all%>% select(xlab, rate2, rate3, rate4, rate5, rate6)
##need to rescale rates
pred_tem<-sapply(pred_tem, as.numeric) ##convert dataframe to numeric
rs2<-rescale(pred_tem[,2], to=c(0,1))
rs3<-rescale(pred_tem[,3], to=c(0,1))
rs4<-rescale(pred_tem[,4], to=c(0,1))
rs5<-rescale(pred_tem[,5], to=c(0,1))
rs6<-rescale(pred_tem[,6], to=c(0,1))

matx_rs2<-matrix(rs2, nrow=131)
data_rs2<-as.data.frame(matx_rs2)
colnames(data_rs2)<-c('scaled_r2')

matx_rs3<-matrix(rs3, nrow=131)
data_rs3<-as.data.frame(matx_rs3)
colnames(data_rs3)<-c('scaled_r3')

matx_rs4<-matrix(rs4, nrow=131)
data_rs4<-as.data.frame(matx_rs4)
colnames(data_rs4)<-c('scaled_r4')

matx_rs5<-matrix(rs5, nrow=131)
data_rs5<-as.data.frame(matx_rs5)
colnames(data_rs5)<-c('scaled_r5')

matx_rs6<-matrix(rs6, nrow=131)
data_rs6<-as.data.frame(matx_rs6)
colnames(data_rs6)<-c('scaled_r6')

temp1<-all%>%select(xlab)
temp2<-cbind(temp1, data_rs2, data_rs3, data_rs4, data_rs5)

pred<-reshape2::melt(temp2, id=c("xlab"))

plot2<-ggplot(data=pred, aes(x=xlab, y=value,color=variable))+ 
  geom_point(aes(color=variable),shape=1,stroke=1,size=2)+
  geom_smooth(aes(color=variable), method=loess, se=FALSE)+
  #scale_x_continuous(limits=c(-1,5))+
  #scale_y_continuous(labels=scaleFUN)+
  #facet_grid(~scen, labeller=as_labeller(trtlab))+
  #scale_fill_manual(values = c("#868686FF","#E7B800", "#0073C2FF","#FC4E07","#00AFBB")) +
  scale_color_manual(values = c("#868686FF","#E7B800","#0073C2FF", "#FC4E07","#00AFBB"))+
  theme_pubr(border=TRUE)+theme(legend.position="none")+theme(strip.text=element_text(size=14, face="bold"))+theme(legend.position="right")
plot2

pdf("scaled_rate_mumax.pdf", width=5.5, height=3.5)
plot2
dev.off() 


temp1<-all%>%select(resp)
temp2<-cbind(temp1, data_rs2, data_rs3, data_rs4, data_rs5)

pred<-reshape2::melt(temp2, id=c("resp"))

plot2<-ggplot(data=pred, aes(x=resp, y=value,color=variable))+ 
  geom_point(aes(color=variable),shape=1,stroke=1,size=2)+
  #geom_smooth(aes(color=variable), method=lm, se=FALSE)+
  geom_abline(slope=0.025, intercept=0, linetype="dashed")+
  #scale_x_continuous(limits=c(-1,5))+
  #scale_y_continuous(labels=scaleFUN)+
  #facet_grid(~scen, labeller=as_labeller(trtlab))+
  #scale_fill_manual(values = c("#868686FF","#E7B800", "#0073C2FF","#FC4E07","#00AFBB")) +
  scale_color_manual(values = c("#868686FF","#E7B800","#0073C2FF", "#FC4E07","#00AFBB"))+
  theme_pubr(border=TRUE)+theme(legend.position="none")+theme(strip.text=element_text(size=14, face="bold"))+theme(legend.position="right")
plot2

pdf("resp 1 to 1.pdf", width=5.5, height=3.5)
plot2
dev.off() 


```

